{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset directory\n",
    "dataset_dir = 'CrossMatch_Sample_DB'\n",
    "\n",
    "# Lists to store image data and labels\n",
    "image_data = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through the dataset and load images and labels\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.lower().endswith('.tif'):  # Check for TIF files, case-insensitive\n",
    "        # Extract labels from the filename\n",
    "        person_id, finger_id, scan_num = filename.split('_')\n",
    "        person_id = int(person_id)  # Convert person ID to an integer\n",
    "        finger_id = int(finger_id)  # Convert finger ID to an integer\n",
    "\n",
    "        # Load the image\n",
    "        img_path = os.path.join(dataset_dir, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            image_data.append(img)\n",
    "            labels.append((person_id, finger_id))\n",
    "\n",
    "# Now 'image_data' contains the loaded images, and 'labels' contains the corresponding labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n"
     ]
    }
   ],
   "source": [
    "print(len(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique persons: 9\n",
      "[12 13 17 22 27 45 47 57 76]\n",
      "Number of unique fingers: 6\n",
      "[3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'labels' list to a NumPy array\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "# Extract individual components: person IDs, finger IDs, and scan numbers\n",
    "person_ids = np.unique(labels_array[:, 0])\n",
    "finger_ids = np.unique(labels_array[:, 1])\n",
    "\n",
    "num_unique_persons = len(person_ids)\n",
    "num_unique_fingers = len(finger_ids)\n",
    "\n",
    "print(\"Number of unique persons:\", num_unique_persons)\n",
    "print(person_ids)\n",
    "print(\"Number of unique fingers:\", num_unique_fingers)\n",
    "print(finger_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "\n",
    "# Extract features using HOG for each image\n",
    "hog_features = []\n",
    "for img in image_data:\n",
    "    hog_img = cv2.resize(img, (64, 128))  # Resize image to a common size for HOG\n",
    "    features = hog.compute(hog_img)\n",
    "    hog_features.append(features.flatten())\n",
    "\n",
    "# Now 'hog_features' contains the extracted HOG features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Combine person_id and finger_id into a single label\n",
    "combined_labels = ['{}_{}'.format(person_id, finger_id) for person_id, finger_id in labels]\n",
    "\n",
    "# Use LabelEncoder to transform the combined labels into encoded integers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(combined_labels)\n",
    "\n",
    "# Now 'encoded_labels' contains the encoded target labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7926829268292683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "features = hog_features  \n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize SVM classifier\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Train the SVM model\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = svm.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
